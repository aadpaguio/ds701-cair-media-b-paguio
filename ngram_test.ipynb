{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8384cb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;32m2\u001b[0m\u001b[1;32m channel Terms of Service accepted\u001b[0m\n",
      "Retrieving notices: done\n",
      "Channels:\n",
      " - rapidsai\n",
      " - conda-forge\n",
      " - defaults\n",
      "Platform: osx-arm64\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: failed\n",
      "\n",
      "PackagesNotFoundError: The following packages are not available from current channels:\n",
      "\n",
      "  - cudf-polars-cu12\n",
      "\n",
      "Current channels:\n",
      "\n",
      "  - https://conda.anaconda.org/rapidsai\n",
      "  - https://conda.anaconda.org/conda-forge\n",
      "  - defaults\n",
      "\n",
      "To search for alternate channels that may provide the conda package you're\n",
      "looking for, navigate to\n",
      "\n",
      "    https://anaconda.org\n",
      "\n",
      "and use the search bar at the top of the page.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda install -c rapidsai -c conda-forge cudf-polars-cu12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61e1b39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8c8dd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import pandas as pd\n",
    "df = sklearn.datasets.fetch_20newsgroups(subset='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "579b9992",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Date</th>\n",
       "      <th>Heading</th>\n",
       "      <th>NewsType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KARACHI: The Sindh government has decided to b...</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>sindh govt decides to cut public transport far...</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HONG KONG: Asian markets started 2015 on an up...</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>asia stocks up in new year trad</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HONG KONG:  Hong Kong shares opened 0.66 perce...</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>hong kong stocks open 0.66 percent lower</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HONG KONG: Asian markets tumbled Tuesday follo...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>asian stocks sink euro near nine year</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NEW YORK: US oil prices Monday slipped below $...</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>us oil prices slip below 50 a barr</td>\n",
       "      <td>business</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article      Date  \\\n",
       "0  KARACHI: The Sindh government has decided to b...  1/1/2015   \n",
       "1  HONG KONG: Asian markets started 2015 on an up...  1/2/2015   \n",
       "2  HONG KONG:  Hong Kong shares opened 0.66 perce...  1/5/2015   \n",
       "3  HONG KONG: Asian markets tumbled Tuesday follo...  1/6/2015   \n",
       "4  NEW YORK: US oil prices Monday slipped below $...  1/6/2015   \n",
       "\n",
       "                                             Heading  NewsType  \n",
       "0  sindh govt decides to cut public transport far...  business  \n",
       "1                    asia stocks up in new year trad  business  \n",
       "2           hong kong stocks open 0.66 percent lower  business  \n",
       "3             asian stocks sink euro near nine year   business  \n",
       "4                 us oil prices slip below 50 a barr  business  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Articles.csv', encoding='latin-1')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c058458",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2692, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc3cb117",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = df.copy()\n",
    "df_pandas['article_id'] = range(1, len(df_pandas) + 1)\n",
    "df_pandas['publication'] = 'Boston Globe'\n",
    "df_pandas = df_pandas.rename(columns={'Date':'date'})\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('punkt', quiet=True)\n",
    "\n",
    "# Initialize lemmatizer and stop words\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Remove stop words and lemmatize text\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    \n",
    "    # Convert to lowercase and remove non-alphabetic characters\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', str(text).lower())\n",
    "    \n",
    "    # Tokenize\n",
    "    words = text.split()\n",
    "    \n",
    "    # Remove stop words and lemmatize\n",
    "    processed_words = [\n",
    "        lemmatizer.lemmatize(word) \n",
    "        for word in words \n",
    "        if word not in stop_words and len(word) > 2\n",
    "    ]\n",
    "    \n",
    "    return ' '.join(processed_words)\n",
    "\n",
    "# Apply preprocessing to Article column\n",
    "df_pandas['Article'] = df_pandas['Article'].apply(preprocess_text)\n",
    "\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# vectorizer = CountVectorizer()\n",
    "# X = vectorizer.fit_transform(df_pandas['text'])\n",
    "# feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "# # Convert sparse matrix to dense and create DataFrame\n",
    "# X_dense = X.toarray()\n",
    "# feature_df = pd.DataFrame(X_dense, columns=feature_names)\n",
    "\n",
    "# # Combine with original metadata\n",
    "# df_pandas = pd.concat([df_pandas[['article_id', 'date', 'publication']], feature_df], axis=1)\n",
    "\n",
    "# print(f\"Shape of count matrix: {X.shape}\")\n",
    "# print(f\"Number of features: {len(feature_names)}\")\n",
    "# print(f\"First 10 features: {feature_names[:10]}\")\n",
    "\n",
    "# df_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bfa5ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer execution time: 1.9710 seconds\n",
      "Shape of count matrix: (2692, 685806)\n",
      "Number of features: 685806\n",
      "First 10 features: ['aabar investment' 'aabar investment biggest' 'aamer ali'\n",
      " 'aamer ali gave' 'aamer ali khawar' 'aamer bismillah'\n",
      " 'aamer bismillah khan' 'aamer ehsan' 'aamer ehsan zulfiqar' 'aamer nazir']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>date</th>\n",
       "      <th>aabar investment</th>\n",
       "      <th>aabar investment biggest</th>\n",
       "      <th>aamer ali</th>\n",
       "      <th>aamer ali gave</th>\n",
       "      <th>aamer ali khawar</th>\n",
       "      <th>aamer bismillah</th>\n",
       "      <th>aamer bismillah khan</th>\n",
       "      <th>aamer ehsan</th>\n",
       "      <th>...</th>\n",
       "      <th>zyl caught</th>\n",
       "      <th>zyl caught end</th>\n",
       "      <th>zyl dean</th>\n",
       "      <th>zyl dean elgar</th>\n",
       "      <th>zyl ended</th>\n",
       "      <th>zyl ended spliced</th>\n",
       "      <th>zyl run</th>\n",
       "      <th>zyl run four</th>\n",
       "      <th>zyl six</th>\n",
       "      <th>zyl six start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1/1/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1/2/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1/5/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1/6/2015</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 685808 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id      date  aabar investment  aabar investment biggest  \\\n",
       "0           1  1/1/2015                 0                         0   \n",
       "1           2  1/2/2015                 0                         0   \n",
       "2           3  1/5/2015                 0                         0   \n",
       "3           4  1/6/2015                 0                         0   \n",
       "4           5  1/6/2015                 0                         0   \n",
       "\n",
       "   aamer ali  aamer ali gave  aamer ali khawar  aamer bismillah  \\\n",
       "0          0               0                 0                0   \n",
       "1          0               0                 0                0   \n",
       "2          0               0                 0                0   \n",
       "3          0               0                 0                0   \n",
       "4          0               0                 0                0   \n",
       "\n",
       "   aamer bismillah khan  aamer ehsan  ...  zyl caught  zyl caught end  \\\n",
       "0                     0            0  ...           0               0   \n",
       "1                     0            0  ...           0               0   \n",
       "2                     0            0  ...           0               0   \n",
       "3                     0            0  ...           0               0   \n",
       "4                     0            0  ...           0               0   \n",
       "\n",
       "   zyl dean  zyl dean elgar  zyl ended  zyl ended spliced  zyl run  \\\n",
       "0         0               0          0                  0        0   \n",
       "1         0               0          0                  0        0   \n",
       "2         0               0          0                  0        0   \n",
       "3         0               0          0                  0        0   \n",
       "4         0               0          0                  0        0   \n",
       "\n",
       "   zyl run four  zyl six  zyl six start  \n",
       "0             0        0              0  \n",
       "1             0        0              0  \n",
       "2             0        0              0  \n",
       "3             0        0              0  \n",
       "4             0        0              0  \n",
       "\n",
       "[5 rows x 685808 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Time the CountVectorizer on Article column\n",
    "start_time = time.time()\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(2,3))\n",
    "X = vectorizer.fit_transform(df_pandas['Article'])\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"CountVectorizer execution time: {end_time - start_time:.4f} seconds\")\n",
    "print(f\"Shape of count matrix: {X.shape}\")\n",
    "print(f\"Number of features: {len(feature_names)}\")\n",
    "print(f\"First 10 features: {feature_names[:10]}\")\n",
    "\n",
    "# Convert sparse matrix to dense and create DataFrame\n",
    "X_dense = X.toarray()\n",
    "feature_df = pd.DataFrame(X_dense, columns=feature_names)\n",
    "\n",
    "# Combine with original metadata\n",
    "df_pandas_fin = pd.concat([df_pandas[['article_id', 'date']], feature_df], axis=1)\n",
    "\n",
    "df_pandas_fin.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27a18138",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngrams_polars(df, text_col=\"text\", n=2):\n",
    "    \"\"\"\n",
    "    Memory-efficient n-gram creation using group_by instead of pivot\n",
    "    \"\"\"\n",
    "    # Step 1: Create the base ngram counts (same as before)\n",
    "    if n == 1:\n",
    "        ngram_counts = (\n",
    "            df.lazy()\n",
    "            .with_columns(\n",
    "                pl.col(text_col)\n",
    "                .str.to_lowercase()\n",
    "                .str.extract_all(r'(?u)\\b\\w\\w+\\b')\n",
    "                .alias(\"words\")\n",
    "            )\n",
    "            .explode(\"words\")\n",
    "            .group_by([\"article_id\", \"date\", \"publication\", \"words\"])\n",
    "            .agg(pl.len().alias(\"count\"))\n",
    "            .rename({\"words\": \"ngram\"})\n",
    "        ).collect()\n",
    "    else:\n",
    "        # Build n-gram logic (same as before)\n",
    "        concat_elements = [pl.element()]\n",
    "        filter_conditions = []\n",
    "        \n",
    "        for i in range(1, n):\n",
    "            concat_elements.append(pl.element().shift(-i))\n",
    "            filter_conditions.append(pl.element().shift(-i).is_not_null())\n",
    "        \n",
    "        combined_filter = filter_conditions[0]\n",
    "        for condition in filter_conditions[1:]:\n",
    "            combined_filter = combined_filter & condition\n",
    "        \n",
    "        ngram_counts = (\n",
    "            df.lazy()\n",
    "            .with_columns(\n",
    "                pl.col(text_col)\n",
    "                .str.to_lowercase()\n",
    "                .str.extract_all(r'(?u)\\b\\w\\w+\\b')\n",
    "                .alias(\"words\")\n",
    "            )\n",
    "            .with_columns(\n",
    "                pl.col(\"words\").list.eval(\n",
    "                    pl.concat_str(concat_elements, separator=\" \")\n",
    "                    .filter(combined_filter)\n",
    "                ).list.drop_nulls().alias(\"ngram\")\n",
    "            )\n",
    "            .select([\"article_id\", \"date\", \"publication\", \"ngram\"])\n",
    "            .explode(\"ngram\")\n",
    "            .group_by([\"article_id\", \"date\", \"publication\", \"ngram\"])\n",
    "            .agg(pl.len().alias(\"count\"))\n",
    "        ).collect(engine='gpu')\n",
    "    \n",
    "    # Step 2: Get vocabulary (for interpretability)\n",
    "    vocabulary = (\n",
    "        ngram_counts\n",
    "        .select(\"ngram\")\n",
    "        .unique()\n",
    "        # .sort(\"ngram\")\n",
    "        # .get_column(\"ngram\")\n",
    "    )\n",
    "    fin_df = (\n",
    "        ngram_counts.lazy()\n",
    "        .group_by(\"article_id\", \"date\", \"publication\")\n",
    "        .agg(*[pl.col('count').filter(pl.col('ngram') == pl.lit(ngram)).sum().alias(f'{ngram}') for ngram in list(vocabulary.to_series())])\n",
    "    ).collect(engine='gpu')\n",
    "    \n",
    "    return fin_df, vocabulary\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "12177a04",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "GPU engine requested, but required package 'cudf_polars' not found.\nPlease install using the command `pip install cudf-polars-cu12` (or `pip install cudf-polars-cu11` if your system has a CUDA 11 driver).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m ngram_cnt, vocab = \u001b[43mcreate_ngrams_polars\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_pandas\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_pandas\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mArticle\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mcreate_ngrams_polars\u001b[39m\u001b[34m(df, text_col, n)\u001b[39m\n\u001b[32m     30\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m condition \u001b[38;5;129;01min\u001b[39;00m filter_conditions[\u001b[32m1\u001b[39m:]:\n\u001b[32m     31\u001b[39m         combined_filter = combined_filter & condition\n\u001b[32m     33\u001b[39m     ngram_counts = \u001b[43m(\u001b[49m\n\u001b[32m     34\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlazy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     36\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     37\u001b[39m \u001b[43m            \u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_lowercase\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m \u001b[43m            \u001b[49m\u001b[43m.\u001b[49m\u001b[43mstr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mextract_all\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m(?u)\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mw\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mw+\u001b[39;49m\u001b[33;43m\\\u001b[39;49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     39\u001b[39m \u001b[43m            \u001b[49m\u001b[43m.\u001b[49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwords\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     40\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mwith_columns\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     42\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwords\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconcat_elements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseparator\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m                \u001b[49m\u001b[43m.\u001b[49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_filter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop_nulls\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mngram\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     46\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marticle_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpublication\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mngram\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mexplode\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mngram\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     49\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43mgroup_by\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43marticle_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdate\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpublication\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mngram\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m        \u001b[49m\u001b[43m.\u001b[49m\u001b[43magg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcount\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mgpu\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Step 2: Get vocabulary (for interpretability)\u001b[39;00m\n\u001b[32m     54\u001b[39m vocabulary = (\n\u001b[32m     55\u001b[39m     ngram_counts\n\u001b[32m     56\u001b[39m     .select(\u001b[33m\"\u001b[39m\u001b[33mngram\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   (...)\u001b[39m\u001b[32m     59\u001b[39m     \u001b[38;5;66;03m# .get_column(\"ngram\")\u001b[39;00m\n\u001b[32m     60\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Work3/lib/python3.11/site-packages/polars/lazyframe/frame.py:2012\u001b[39m, in \u001b[36mLazyFrame.collect\u001b[39m\u001b[34m(self, type_coercion, predicate_pushdown, projection_pushdown, simplify_expression, slice_pushdown, comm_subplan_elim, comm_subexpr_elim, cluster_with_columns, no_optimization, streaming, engine, background, _eager, **_kwargs)\u001b[39m\n\u001b[32m   2010\u001b[39m callback = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_gpu:\n\u001b[32m-> \u001b[39m\u001b[32m2012\u001b[39m     cudf_polars = \u001b[43mimport_optional\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2013\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcudf_polars\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2014\u001b[39m \u001b[43m        \u001b[49m\u001b[43merr_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGPU engine requested, but required package\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2015\u001b[39m \u001b[43m        \u001b[49m\u001b[43minstall_message\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2016\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPlease install using the command `pip install cudf-polars-cu12` \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2017\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m(or `pip install cudf-polars-cu11` if your system has a \u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2018\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCUDA 11 driver).\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   2019\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2020\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2021\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_config_obj:\n\u001b[32m   2022\u001b[39m         engine = GPUEngine()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/Work3/lib/python3.11/site-packages/polars/dependencies.py:280\u001b[39m, in \u001b[36mimport_optional\u001b[39m\u001b[34m(module_name, err_prefix, err_suffix, min_version, min_err_prefix, install_message)\u001b[39m\n\u001b[32m    275\u001b[39m     suffix = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merr_suffix.strip(\u001b[33m'\u001b[39m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_suffix \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    276\u001b[39m     err_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m + (\n\u001b[32m    277\u001b[39m         install_message\n\u001b[32m    278\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPlease install using the command `pip install \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_root\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    279\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m(err_message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    282\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m min_version:\n\u001b[32m    283\u001b[39m     min_version = parse_version(min_version)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: GPU engine requested, but required package 'cudf_polars' not found.\nPlease install using the command `pip install cudf-polars-cu12` (or `pip install cudf-polars-cu11` if your system has a CUDA 11 driver)."
     ]
    }
   ],
   "source": [
    "ngram_cnt, vocab = create_ngrams_polars(pl.from_pandas(df_pandas), n=2, text_col='Article')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60b9275f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_692, 295_255)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>article_id</th><th>date</th><th>publication</th><th>farmer welfare</th><th>based fixing</th><th>get cricket</th><th>rasool second</th><th>would cease</th><th>busy home</th><th>yasser corona</th><th>cpec envisions</th><th>weightlifter extended</th><th>history growing</th><th>ominous claycourt</th><th>manager afinitithe</th><th>turning legbreak</th><th>respect civil</th><th>done scale</th><th>sammys tenth</th><th>sand reservoir</th><th>hike sign</th><th>year got</th><th>intent lucky</th><th>day image</th><th>car rental</th><th>platinum gained</th><th>strongthe governor</th><th>flew oversebastian</th><th>led varying</th><th>giving memento</th><th>career slowed</th><th>dollar spur</th><th>dont contemplate</th><th>perennial hope</th><th>get wrong</th><th>research institute</th><th>system action</th><th>&hellip;</th><th>news priced</th><th>seventh seed</th><th>day playbadar</th><th>saying wanted</th><th>useful help</th><th>bale scorer</th><th>rider jorge</th><th>rose opening</th><th>situation led</th><th>breakthrough removing</th><th>account order</th><th>odis three</th><th>coming image</th><th>meldonium australian</th><th>decrease took</th><th>lot strength</th><th>calling people</th><th>head saab</th><th>around worldthis</th><th>called july</th><th>notehedge fund</th><th>lord thursday</th><th>gone unnoticed</th><th>china move</th><th>made mandatory</th><th>conference roland</th><th>improving law</th><th>back sanction</th><th>added want</th><th>cameo first</th><th>china tumbling</th><th>saidbr brsimbal</th><th>numero uno</th><th>looking service</th><th>unexpectedly smooth</th><th>following recent</th><th>innes senior</th></tr><tr><td>i64</td><td>str</td><td>str</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>&hellip;</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td><td>u32</td></tr></thead><tbody><tr><td>1234</td><td>&quot;2/14/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>189</td><td>&quot;6/23/2015&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>737</td><td>&quot;6/22/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>892</td><td>&quot;8/11/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2684</td><td>&quot;3/20/2017&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>380</td><td>&quot;12/8/2015&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1056</td><td>&quot;1/9/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1484</td><td>&quot;3/21/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>2467</td><td>&quot;10/26/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr><tr><td>1559</td><td>&quot;3/31/2016&quot;</td><td>&quot;Boston Globe&quot;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>&hellip;</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_692, 295_255)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ article_i ┆ date      ┆ publicati ┆ farmer    ┆ … ┆ looking   ┆ unexpecte ┆ following ┆ innes    │\n",
       "│ d         ┆ ---       ┆ on        ┆ welfare   ┆   ┆ service   ┆ dly       ┆ recent    ┆ senior   │\n",
       "│ ---       ┆ str       ┆ ---       ┆ ---       ┆   ┆ ---       ┆ smooth    ┆ ---       ┆ ---      │\n",
       "│ i64       ┆           ┆ str       ┆ u32       ┆   ┆ u32       ┆ ---       ┆ u32       ┆ u32      │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ u32       ┆           ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ 1234      ┆ 2/14/2016 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 189       ┆ 6/23/2015 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 737       ┆ 6/22/2016 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 892       ┆ 8/11/2016 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2684      ┆ 3/20/2017 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ …         ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …        │\n",
       "│ 380       ┆ 12/8/2015 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1056      ┆ 1/9/2016  ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1484      ┆ 3/21/2016 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 2467      ┆ 10/26/201 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆ 6         ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ 1559      ┆ 3/31/2016 ┆ Boston    ┆ 0         ┆ … ┆ 0         ┆ 0         ┆ 0         ┆ 0        │\n",
       "│           ┆           ┆ Globe     ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ngram_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8415dcde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
